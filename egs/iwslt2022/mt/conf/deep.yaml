arch: transformer
share-decoder-input-output-embed: True
optimizer: adam
#clip-norm: 10.0
lr-scheduler: inverse_sqrt
warmup-init-lr: 1e-7
warmup-updates: 1000
lr: 2e-4
adam_betas: (0.9,0.997)

criterion: label_smoothed_cross_entropy
label_smoothing: 0.1

dropout: 0.1
attention-dropout: 0.1
activation-dropout: 0.1

activation-fn: relu
encoder-normalize-before: True
decoder-normalize-before: True
encoder-embed-dim: 512
encoder-ffn-embed-dim: 2048
encoder-layers: 30
decoder-layers: 6
encoder-attention-heads: 8

decoder-embed-dim: 512
decoder-ffn-embed-dim: 2048
decoder-attention-heads: 8

load-pretrained-encoder-from: /home/xuchen/st/checkpoints/wmt20/mt/0317_unified_lcrm_tok_deep_baseline_pretrain/avg_5_checkpoint.pt
load-pretrained-decoder-from: /home/xuchen/st/checkpoints/wmt20/mt/0317_unified_lcrm_tok_deep_baseline_pretrain/avg_5_checkpoint.pt
